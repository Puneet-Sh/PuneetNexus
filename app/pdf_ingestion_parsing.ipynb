{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1996be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\puneetsharma\\puneetnexus\\puneetnexus_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e839301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "class PuneetPDFProcessor:\n",
    "    def __init__(self,chunk_size=1000,chunk_overlap=100):\n",
    "        self.chunk_size=chunk_size,\n",
    "        self.chunk_overlap=chunk_overlap,\n",
    "        self.text_splitter=RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\" \"],\n",
    "\n",
    "        )\n",
    "\n",
    "    def process_pdf(self,pdf_path:str)->List[Document]:\n",
    "\n",
    "        loader=PyPDFLoader(pdf_path)\n",
    "        pages=loader.load()\n",
    "\n",
    "        processed_chunks=[]\n",
    "\n",
    "        for page_num,page in enumerate(pages):\n",
    "            cleaned_text=self._clean_text(page.page_content)\n",
    "\n",
    "            if len(cleaned_text.strip()) < 50:\n",
    "                continue\n",
    "\n",
    "            chunks = self.text_splitter.create_documents(\n",
    "                texts=[cleaned_text],\n",
    "                metadatas=[{\n",
    "                    **page.metadata,\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"total_pages\": len(pages),\n",
    "                    \"chunk_method\": \"smart_pdf_processor\",\n",
    "                    \"char_count\": len(cleaned_text)\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            processed_chunks.extend(chunks)\n",
    "\n",
    "        return processed_chunks\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \n",
    "        text = \" \".join(text.split())\n",
    "        \n",
    "        text = text.replace(\"ﬁ\", \"fi\")\n",
    "        text = text.replace(\"ﬂ\", \"fl\")\n",
    "        \n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c82e5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PuneetPDFProcessor at 0x1a364b46b30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor=PuneetPDFProcessor()\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e8e5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed into 14 smart chunks\n",
      "\n",
      "Sample chunk metadata:\n",
      "  producer: Skia/PDF m142 Google Docs Renderer\n",
      "  creator: PyPDF\n",
      "  creationdate: \n",
      "  title: dummy_text_projects\n",
      "  source: ../documents/dummy_pdf.pdf\n",
      "  total_pages: 5\n",
      "  page: 1\n",
      "  page_label: 1\n",
      "  chunk_method: smart_pdf_processor\n",
      "  char_count: 2059\n"
     ]
    }
   ],
   "source": [
    "# Process a PDF if available\n",
    "try:\n",
    "    smart_chunks=preprocessor.process_pdf(\"../documents/dummy_pdf.pdf\")\n",
    "    print(f\"Processed into {len(smart_chunks)} smart chunks\")\n",
    "\n",
    "    if smart_chunks:\n",
    "        print(\"\\nSample chunk metadata:\")\n",
    "        for key, value in smart_chunks[0].metadata.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Processing error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d134ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
